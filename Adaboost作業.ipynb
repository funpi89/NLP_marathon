{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的:了解Ensemble中的Blending與Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: 請描述Blending與Stacking的差異\n",
    "\n",
    "Answer:Stacking是整合方法之一\n",
    "下面分析計算流程，假設第一層有n個子模型，每個模型進行K折交叉驗證\n",
    "1、單個模型分別進行學習\n",
    "首先，採用交叉驗證+網格搜尋，得到子模型最優超引數\n",
    "然後，在此最優超引數下，每次進行交叉驗證時，都會訓練得到一個模型。用此模型對驗證集和測試集分別預測，共進行K次預測，得到一個完整的訓練集預測值和K個測試集預測值，對K個測試集預測值取平均，從而得到一個完整的訓練集預測值和一個測試集預測值\n",
    "2、確定新的訓練集合測試集\n",
    "首先，對n個子模型分別學習，得到n個訓練集預測值（不取平均值），作為n維特徵作為第二層模型的輸入\n",
    "同樣，n個子模型也得到n個測試集預測值，作為第二層模型的輸入\n",
    "3、第二層模型學習\n",
    "用新的特徵構成的訓練集和測試集進行預測\n",
    "注：stacking在交叉驗證時存在資料洩露，容易過擬合\n",
    "\n",
    "Blending整合方法之一\n",
    "Blending直接用不相交的資料集用於不同層的訓練，也就是不作交叉驗證，而是將訓練集分為70%，30%兩部分，由70%訓練模型，對30%和test預測，結果為新特徵輸入，從而不會出現stacking中的資料洩露現象\n",
    "以兩層的Blending為例，訓練集劃分為兩部分（d1，d2），測試集為test\n",
    "第一層：用d1訓練多個模型，將其對d2和test的預測結果作為第二層的New Features\n",
    "第二層：用d2的New Features和標籤訓練新的分類器，然後把test的New Features輸入作為最終的預測值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
