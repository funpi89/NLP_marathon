{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "word2vec高速化_作業.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/funpi89/NLP_marathon/blob/main/word2vec%E9%AB%98%E9%80%9F%E5%8C%96_%E4%BD%9C%E6%A5%AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5Pf_RxOIAYv"
      },
      "source": [
        "### 作業目的: 透過實作加速版word2vec Skip-gram模型來更加了解高速版的word2vec\n",
        "\n",
        "本次作業會採用Penn Tree Bank資料及，學員可以在ptb.train.txt中取得訓練文本資料。這次作業可以讓學員練習到以pytorch搭建模型與進行文本資料的前處理\n",
        "\n",
        "PS: 建議學員使用Colab (或可以使用GPU加速的機器)來進行作業，不然訓練會訓練到天荒地老....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO-a6e2OI5zg"
      },
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAHlppf8T-bf",
        "outputId": "7cd3e4a9-c638-4887-9c85-07ec0e103e86"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e80yAgQSUODz"
      },
      "source": [
        "# Import Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yjz-fWmbJRPB"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import tqdm\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import urllib.request\n",
        "from typing import List\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9xrgPu3KBgJ",
        "outputId": "ea7de470-4b05-43af-eaa8-69941df722c4"
      },
      "source": [
        "# 讀取資料\n",
        "\n",
        "# Penn Tree Back dataset\n",
        "with open(\"/content/drive/MyDrive/NLPMarathon/ptb.train.txt\", encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    \n",
        "print(f\"Total {len(lines)} lines\")\n",
        "raw_dataset = [line.split() for line in lines]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 42068 lines\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAcF_5CQKH_J",
        "outputId": "269b1a3b-584c-4f3e-ed9a-503872772241"
      },
      "source": [
        "# 查看前5筆\n",
        "raw_dataset[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['aer',\n",
              "  'banknote',\n",
              "  'berlitz',\n",
              "  'calloway',\n",
              "  'centrust',\n",
              "  'cluett',\n",
              "  'fromstein',\n",
              "  'gitano',\n",
              "  'guterman',\n",
              "  'hydro-quebec',\n",
              "  'ipo',\n",
              "  'kia',\n",
              "  'memotec',\n",
              "  'mlx',\n",
              "  'nahb',\n",
              "  'punts',\n",
              "  'rake',\n",
              "  'regatta',\n",
              "  'rubens',\n",
              "  'sim',\n",
              "  'snack-food',\n",
              "  'ssangyong',\n",
              "  'swapo',\n",
              "  'wachter'],\n",
              " ['pierre',\n",
              "  '<unk>',\n",
              "  'N',\n",
              "  'years',\n",
              "  'old',\n",
              "  'will',\n",
              "  'join',\n",
              "  'the',\n",
              "  'board',\n",
              "  'as',\n",
              "  'a',\n",
              "  'nonexecutive',\n",
              "  'director',\n",
              "  'nov.',\n",
              "  'N'],\n",
              " ['mr.',\n",
              "  '<unk>',\n",
              "  'is',\n",
              "  'chairman',\n",
              "  'of',\n",
              "  '<unk>',\n",
              "  'n.v.',\n",
              "  'the',\n",
              "  'dutch',\n",
              "  'publishing',\n",
              "  'group'],\n",
              " ['rudolph',\n",
              "  '<unk>',\n",
              "  'N',\n",
              "  'years',\n",
              "  'old',\n",
              "  'and',\n",
              "  'former',\n",
              "  'chairman',\n",
              "  'of',\n",
              "  'consolidated',\n",
              "  'gold',\n",
              "  'fields',\n",
              "  'plc',\n",
              "  'was',\n",
              "  'named',\n",
              "  'a',\n",
              "  'nonexecutive',\n",
              "  'director',\n",
              "  'of',\n",
              "  'this',\n",
              "  'british',\n",
              "  'industrial',\n",
              "  'conglomerate'],\n",
              " ['a',\n",
              "  'form',\n",
              "  'of',\n",
              "  'asbestos',\n",
              "  'once',\n",
              "  'used',\n",
              "  'to',\n",
              "  'make',\n",
              "  'kent',\n",
              "  'cigarette',\n",
              "  'filters',\n",
              "  'has',\n",
              "  'caused',\n",
              "  'a',\n",
              "  'high',\n",
              "  'percentage',\n",
              "  'of',\n",
              "  'cancer',\n",
              "  'deaths',\n",
              "  'among',\n",
              "  'a',\n",
              "  'group',\n",
              "  'of',\n",
              "  'workers',\n",
              "  'exposed',\n",
              "  'to',\n",
              "  'it',\n",
              "  'more',\n",
              "  'than',\n",
              "  'N',\n",
              "  'years',\n",
              "  'ago',\n",
              "  'researchers',\n",
              "  'reported']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oki6AxhJyj4",
        "outputId": "2a9c1105-5ebd-459c-8eb2-532e90020962"
      },
      "source": [
        "# 定義資料前處理函示\n",
        "class PreProcessor():\n",
        "    '''Function to do preprocess of input corpus\n",
        "    Parameters\n",
        "    -----------\n",
        "    corpus: str\n",
        "        input corpus to be processed\n",
        "    only_word: bool\n",
        "        whether to filter out non-word\n",
        "    min_freq: int\n",
        "        minimum frequency of a word to be kept\n",
        "    do_subsampling: bool\n",
        "        whether to do subsampling\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, only_word: bool=False, min_freq: int=5, do_subsampling: bool=True, t: float=1e-5):\n",
        "        self.only_word = only_word\n",
        "        self.min_freq = min_freq\n",
        "        self.do_subsampling = do_subsampling\n",
        "        self.t = t\n",
        "    \n",
        "    def process(self, corpus: List[str]):\n",
        "        \n",
        "        word_dic = set()\n",
        "        counter = Counter()\n",
        "        processed_sentence = []\n",
        "        \n",
        "        for sentence in corpus:\n",
        "        \n",
        "            # hint: 請計算字詞頻率\n",
        "            counter.update(sentence)\n",
        "            processed_sentence.append(sentence)\n",
        "        # hint: 移除頻率過小的字詞 建立word2idx與idx2word與word_frequency辭典\n",
        "        word_cnt = dict(filter(lambda x: x[1] > self.min_freq, counter.items()))\n",
        "        self.word2idx = {word: idx for idx, word in enumerate(word_cnt.keys(), 0)}\n",
        "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
        "        self.word_frequency = word_cnt.copy()\n",
        "        \n",
        "        #將文本轉為ID型式與移除文本中頻率過小的文字\n",
        "        self.processed_corpus = [[self.word2idx[word] for word in line if word in self.word2idx] for line in processed_sentence]\n",
        "        self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
        "        print(f\"Before subsampling: {self.total_num_words} words\")\n",
        "        \n",
        "        # 進行二次採樣(subsampling)\n",
        "        if self.do_subsampling:\n",
        "            self.processed_corpus = [[idx for idx in line if not self.subsampling(idx)] for line in self.processed_corpus]\n",
        "            self.total_num_words = sum([len(line) for line in self.processed_corpus])\n",
        "            counter = Counter([self.idx2word[idx] for line in self.processed_corpus for idx in line])\n",
        "            word_cnt = dict(counter.items())\n",
        "            self.word_frequency = word_cnt.copy()\n",
        "            print(f\"After subsampling: {self.total_num_words} words\")\n",
        "        \n",
        "        # hint: 移除空字串\n",
        "        self.processed_corpus = [[idx for idx in line] for line in self.processed_corpus if len(line) != 0]\n",
        "        \n",
        "        return self.processed_corpus, self.word2idx, self.idx2word, self.word_frequency, self.total_num_words\n",
        "    \n",
        "    def subsampling(self, idx):\n",
        "        \n",
        "        # hint: 學員可以參考講義的subsampling公式(也可自己定義一個)\n",
        "        p = self.t / self.word_frequency[self.idx2word[idx]] * self.total_num_words\n",
        "        p_w = math.sqrt(p) + p\n",
        "        return random.uniform(0, 1) < p_w\n",
        "\n",
        "\n",
        "# 進行資料前處理\n",
        "# 這邊我們subsampling的t取1e-4\n",
        "pre_processor = PreProcessor(True, 5, True, 1e-4)\n",
        "corpus, word2idx, idx2word, word2freq, total_num_words = pre_processor.process(raw_dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before subsampling: 885720 words\n",
            "After subsampling: 448741 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfDuJuT5Kkvl"
      },
      "source": [
        "### 定義Skip-gram使用的Dataset與collate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DraniEYMKfWl"
      },
      "source": [
        "# 客製化Dataset\n",
        "class SkipGramGetAllDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, corpus, word2freq, word2idx, idx2word, window_size, num_negatives):\n",
        "        self.corpus = corpus\n",
        "        self.word2freq = word2freq\n",
        "        self.word2idx = word2idx\n",
        "        self.idx2word = idx2word\n",
        "        self.window_size = window_size\n",
        "        self.num_negatives = num_negatives\n",
        "        \n",
        "        self.all_targets, self.all_contexts = self._get_all_contexts_targets()\n",
        "        self.all_negatives = self._get_all_negatives()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.all_targets)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # hint: 這裡我們會返回 目標字詞，上下文，負採樣樣本\n",
        "        return (self.all_targets[idx], self.all_contexts[idx], self.all_negatives[idx])\n",
        "        \n",
        "    \n",
        "    def _get_all_contexts_targets(self):\n",
        "        all_targets = []\n",
        "        all_contexts = []\n",
        "        \n",
        "        for line in self.corpus:\n",
        "            if len(line) < 2*self.window_size + 1:\n",
        "                continue\n",
        "            \n",
        "            # hint: 這邊我們要創建上下文 (考慮window_size)\n",
        "            all_contexts += line[self.window_size:-self.window_size]\n",
        "            \n",
        "            for index in range(self.window_size, len(line) - self.window_size):\n",
        "                # hint: 創建目標字詞\n",
        "                indices = list(range(max(0, index - self.window_size), min(len(line), index + self.window_size + 1)))\n",
        "                indices.remove(index)\n",
        "                all_targets.append([line[idx] for idx in indices])\n",
        "                               \n",
        "        return all_targets, all_contexts\n",
        "                               \n",
        "    \n",
        "    def _get_all_negatives(self):\n",
        "        \n",
        "        # hint: 進行負採樣，若沒頭緒的學員可以參考實作範例\n",
        "        \n",
        "        cur_exists_words = list(self.word2freq.keys())\n",
        "        sampling_weights = [self.word2freq[word]**0.75 for word in self.word2freq]\n",
        "        population = list(range(len(sampling_weights)))\n",
        "        \n",
        "        all_negatives = []\n",
        "        neg_candidate = []\n",
        "        i = 0\n",
        "        for targets in self.all_targets:\n",
        "            negatives = []\n",
        "            while len(negatives) < self.num_negatives:\n",
        "                if i == len(neg_candidate):\n",
        "                    neg_candidate = random.choices(population, sampling_weights, k=int(1e5))\n",
        "                    neg_candidate = list(map(lambda x: self.word2idx[cur_exists_words[x]], neg_candidate))\n",
        "                    i = 0\n",
        "                \n",
        "                if neg_candidate[i] not in targets:\n",
        "                    negatives.append(neg_candidate[i])\n",
        "                i += 1\n",
        "            all_negatives.append(negatives)      \n",
        "        \n",
        "        return all_negatives\n",
        "    \n",
        "# 客製化collate_fn\n",
        "def skipgram_collate(data):\n",
        "    contexts = []\n",
        "    target_negative = []\n",
        "    labels = []\n",
        "    for target, context, negative in data:\n",
        "        # hint: 將目標字詞、上下文與負採樣樣本個別打包\n",
        "        target_negative += [target + negative]\n",
        "        labels += [[1] * len(target) + [0] * len(negative)]\n",
        "        contexts += [context]\n",
        "    \n",
        "    return torch.tensor(contexts), torch.tensor(target_negative), torch.tensor(labels)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s94kJ0lKKzG5"
      },
      "source": [
        "### 定義Skip-gram模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyyQyLxcKpv1"
      },
      "source": [
        "class SkipGram(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size):\n",
        "        super(SkipGram, self).__init__()\n",
        "        \n",
        "        self.in_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.out_embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        \n",
        "    def forward(self, contexts, targets):\n",
        "        v = self.in_embedding(contexts)\n",
        "        u = self.out_embedding(targets)\n",
        "        \n",
        "        # do dot product to get output\n",
        "        pred = torch.matmul(v[:,None,:], u.permute(0,2,1))\n",
        "        \n",
        "        return pred.squeeze(dim=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHZIFz7yK5An"
      },
      "source": [
        "### 訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hr4sVBd8K10T"
      },
      "source": [
        "# Define hyperparameters\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "verbose = True\n",
        "num_epochs = 100\n",
        "batch_size = 512\n",
        "embed_size = 100\n",
        "lr = 0.01\n",
        "\n",
        "model = SkipGram(len(word2idx), embed_size)\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "    \n",
        "criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "dataset = SkipGramGetAllDataset(corpus, word2freq, word2idx, idx2word, 1, 5)\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=skipgram_collate)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sE28LW2_LB0I",
        "outputId": "cb6fa844-6f41-41b3-81fc-1d64c1b2936e"
      },
      "source": [
        "# Start training\n",
        "\n",
        "lst_loss = []\n",
        "model.train()\n",
        "for epc in tqdm.tqdm(range(num_epochs)):\n",
        "    batch_loss = 0\n",
        "\n",
        "    for i, (contexts, target_negative, labels) in enumerate(loader, 1):\n",
        "        # hint: 開始訓練前要先將optimizer的梯度歸零\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        if use_cuda:\n",
        "            contexts = contexts.cuda()\n",
        "            target_negative = target_negative.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        pred = model(contexts, target_negative)\n",
        "        loss = criterion(pred.float(), labels.float())\n",
        "        batch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if i % 500 == 0:\n",
        "            print(f\"Epoch: {epc + 1}/{num_epochs}, Batch: {i+1}/{len(dataset)/batch_size} Loss: {batch_loss / i:.5f}\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"Epoch: {epc + 1}/{num_epochs}, Loss: {batch_loss / i:.5f}\")\n",
        "    \n",
        "    lst_loss.append(batch_loss/i)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Batch: 501/714.939453125 Loss: 1.05061\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  1%|          | 1/100 [00:02<04:22,  2.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/100, Loss: 0.91762\n",
            "Epoch: 2/100, Batch: 501/714.939453125 Loss: 0.55356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  2%|▏         | 2/100 [00:04<04:07,  2.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2/100, Loss: 0.55003\n",
            "Epoch: 3/100, Batch: 501/714.939453125 Loss: 0.52705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  3%|▎         | 3/100 [00:07<03:55,  2.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3/100, Loss: 0.52675\n",
            "Epoch: 4/100, Batch: 501/714.939453125 Loss: 0.51818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 4/100 [00:09<03:54,  2.44s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4/100, Loss: 0.51828\n",
            "Epoch: 5/100, Batch: 501/714.939453125 Loss: 0.51243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 5/100 [00:11<03:46,  2.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5/100, Loss: 0.51282\n",
            "Epoch: 6/100, Batch: 501/714.939453125 Loss: 0.50848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 6/100 [00:14<03:41,  2.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6/100, Loss: 0.50928\n",
            "Epoch: 7/100, Batch: 501/714.939453125 Loss: 0.50591\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 7/100 [00:16<03:40,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7/100, Loss: 0.50672\n",
            "Epoch: 8/100, Batch: 501/714.939453125 Loss: 0.50410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 8/100 [00:18<03:37,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8/100, Loss: 0.50487\n",
            "Epoch: 9/100, Batch: 501/714.939453125 Loss: 0.50266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  9%|▉         | 9/100 [00:21<03:33,  2.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9/100, Loss: 0.50352\n",
            "Epoch: 10/100, Batch: 501/714.939453125 Loss: 0.50170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 10/100 [00:23<03:33,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/100, Loss: 0.50272\n",
            "Epoch: 11/100, Batch: 501/714.939453125 Loss: 0.50078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 11%|█         | 11/100 [00:25<03:27,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11/100, Loss: 0.50213\n",
            "Epoch: 12/100, Batch: 501/714.939453125 Loss: 0.50070\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 12/100 [00:28<03:21,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12/100, Loss: 0.50164\n",
            "Epoch: 13/100, Batch: 501/714.939453125 Loss: 0.49999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 13/100 [00:30<03:22,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13/100, Loss: 0.50121\n",
            "Epoch: 14/100, Batch: 501/714.939453125 Loss: 0.49983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 14%|█▍        | 14/100 [00:32<03:17,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14/100, Loss: 0.50080\n",
            "Epoch: 15/100, Batch: 501/714.939453125 Loss: 0.49984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 15/100 [00:34<03:12,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15/100, Loss: 0.50078\n",
            "Epoch: 16/100, Batch: 501/714.939453125 Loss: 0.49932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 16/100 [00:37<03:13,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16/100, Loss: 0.50056\n",
            "Epoch: 17/100, Batch: 501/714.939453125 Loss: 0.49963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 17/100 [00:39<03:11,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17/100, Loss: 0.50049\n",
            "Epoch: 18/100, Batch: 501/714.939453125 Loss: 0.49917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 18/100 [00:41<03:08,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18/100, Loss: 0.50024\n",
            "Epoch: 19/100, Batch: 501/714.939453125 Loss: 0.49910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 19%|█▉        | 19/100 [00:44<03:06,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19/100, Loss: 0.50021\n",
            "Epoch: 20/100, Batch: 501/714.939453125 Loss: 0.49886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 20/100 [00:46<03:01,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20/100, Loss: 0.50008\n",
            "Epoch: 21/100, Batch: 501/714.939453125 Loss: 0.49912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 21/100 [00:48<02:57,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21/100, Loss: 0.50004\n",
            "Epoch: 22/100, Batch: 501/714.939453125 Loss: 0.49933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 22/100 [00:50<02:57,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22/100, Loss: 0.49996\n",
            "Epoch: 23/100, Batch: 501/714.939453125 Loss: 0.49866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 23%|██▎       | 23/100 [00:53<02:53,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23/100, Loss: 0.49993\n",
            "Epoch: 24/100, Batch: 501/714.939453125 Loss: 0.49837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 24/100 [00:55<02:54,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24/100, Loss: 0.49983\n",
            "Epoch: 25/100, Batch: 501/714.939453125 Loss: 0.49853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 25/100 [00:57<02:54,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25/100, Loss: 0.49969\n",
            "Epoch: 26/100, Batch: 501/714.939453125 Loss: 0.49842\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 26%|██▌       | 26/100 [01:00<02:54,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26/100, Loss: 0.49966\n",
            "Epoch: 27/100, Batch: 501/714.939453125 Loss: 0.49890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 27/100 [01:02<02:52,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27/100, Loss: 0.49968\n",
            "Epoch: 28/100, Batch: 501/714.939453125 Loss: 0.49856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 28/100 [01:05<02:52,  2.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28/100, Loss: 0.49959\n",
            "Epoch: 29/100, Batch: 501/714.939453125 Loss: 0.49853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 29/100 [01:07<02:45,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29/100, Loss: 0.49959\n",
            "Epoch: 30/100, Batch: 501/714.939453125 Loss: 0.49844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 30/100 [01:09<02:40,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30/100, Loss: 0.49959\n",
            "Epoch: 31/100, Batch: 501/714.939453125 Loss: 0.49839\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 31%|███       | 31/100 [01:11<02:40,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31/100, Loss: 0.49951\n",
            "Epoch: 32/100, Batch: 501/714.939453125 Loss: 0.49830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 32/100 [01:14<02:38,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32/100, Loss: 0.49944\n",
            "Epoch: 33/100, Batch: 501/714.939453125 Loss: 0.49855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 33/100 [01:16<02:36,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33/100, Loss: 0.49943\n",
            "Epoch: 34/100, Batch: 501/714.939453125 Loss: 0.49811\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 34/100 [01:18<02:34,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34/100, Loss: 0.49940\n",
            "Epoch: 35/100, Batch: 501/714.939453125 Loss: 0.49838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 35/100 [01:21<02:30,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35/100, Loss: 0.49937\n",
            "Epoch: 36/100, Batch: 501/714.939453125 Loss: 0.49826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 36/100 [01:23<02:25,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36/100, Loss: 0.49932\n",
            "Epoch: 37/100, Batch: 501/714.939453125 Loss: 0.49810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 37%|███▋      | 37/100 [01:25<02:22,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37/100, Loss: 0.49937\n",
            "Epoch: 38/100, Batch: 501/714.939453125 Loss: 0.49817\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 38/100 [01:28<02:23,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38/100, Loss: 0.49932\n",
            "Epoch: 39/100, Batch: 501/714.939453125 Loss: 0.49810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 39%|███▉      | 39/100 [01:30<02:18,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39/100, Loss: 0.49925\n",
            "Epoch: 40/100, Batch: 501/714.939453125 Loss: 0.49845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 40/100 [01:32<02:15,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40/100, Loss: 0.49925\n",
            "Epoch: 41/100, Batch: 501/714.939453125 Loss: 0.49813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 41%|████      | 41/100 [01:34<02:16,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 41/100, Loss: 0.49926\n",
            "Epoch: 42/100, Batch: 501/714.939453125 Loss: 0.49830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 42/100 [01:37<02:17,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 42/100, Loss: 0.49922\n",
            "Epoch: 43/100, Batch: 501/714.939453125 Loss: 0.49795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 43%|████▎     | 43/100 [01:39<02:15,  2.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 43/100, Loss: 0.49924\n",
            "Epoch: 44/100, Batch: 501/714.939453125 Loss: 0.49816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 44/100 [01:42<02:16,  2.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 44/100, Loss: 0.49921\n",
            "Epoch: 45/100, Batch: 501/714.939453125 Loss: 0.49787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 45/100 [01:44<02:10,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 45/100, Loss: 0.49920\n",
            "Epoch: 46/100, Batch: 501/714.939453125 Loss: 0.49815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 46/100 [01:46<02:06,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 46/100, Loss: 0.49917\n",
            "Epoch: 47/100, Batch: 501/714.939453125 Loss: 0.49798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 47/100 [01:49<02:06,  2.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 47/100, Loss: 0.49911\n",
            "Epoch: 48/100, Batch: 501/714.939453125 Loss: 0.49792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 48/100 [01:51<02:04,  2.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 48/100, Loss: 0.49918\n",
            "Epoch: 49/100, Batch: 501/714.939453125 Loss: 0.49814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 49%|████▉     | 49/100 [01:54<01:59,  2.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49/100, Loss: 0.49912\n",
            "Epoch: 50/100, Batch: 501/714.939453125 Loss: 0.49800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 50/100 [01:56<01:58,  2.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50/100, Loss: 0.49917\n",
            "Epoch: 51/100, Batch: 501/714.939453125 Loss: 0.49840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 51%|█████     | 51/100 [01:58<01:54,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 51/100, Loss: 0.49919\n",
            "Epoch: 52/100, Batch: 501/714.939453125 Loss: 0.49782\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 52/100 [02:01<01:52,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 52/100, Loss: 0.49906\n",
            "Epoch: 53/100, Batch: 501/714.939453125 Loss: 0.49794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 53/100 [02:03<01:50,  2.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 53/100, Loss: 0.49909\n",
            "Epoch: 54/100, Batch: 501/714.939453125 Loss: 0.49775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 54/100 [02:05<01:47,  2.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 54/100, Loss: 0.49905\n",
            "Epoch: 55/100, Batch: 501/714.939453125 Loss: 0.49833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 55/100 [02:08<01:44,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 55/100, Loss: 0.49909\n",
            "Epoch: 56/100, Batch: 501/714.939453125 Loss: 0.49830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 56/100 [02:10<01:42,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 56/100, Loss: 0.49910\n",
            "Epoch: 57/100, Batch: 501/714.939453125 Loss: 0.49838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 57%|█████▋    | 57/100 [02:12<01:39,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 57/100, Loss: 0.49915\n",
            "Epoch: 58/100, Batch: 501/714.939453125 Loss: 0.49778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 58/100 [02:14<01:36,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 58/100, Loss: 0.49904\n",
            "Epoch: 59/100, Batch: 501/714.939453125 Loss: 0.49792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 59%|█████▉    | 59/100 [02:17<01:34,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 59/100, Loss: 0.49909\n",
            "Epoch: 60/100, Batch: 501/714.939453125 Loss: 0.49784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 60/100 [02:19<01:30,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 60/100, Loss: 0.49912\n",
            "Epoch: 61/100, Batch: 501/714.939453125 Loss: 0.49787\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 61%|██████    | 61/100 [02:21<01:27,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 61/100, Loss: 0.49907\n",
            "Epoch: 62/100, Batch: 501/714.939453125 Loss: 0.49794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▏   | 62/100 [02:24<01:27,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 62/100, Loss: 0.49902\n",
            "Epoch: 63/100, Batch: 501/714.939453125 Loss: 0.49783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 63%|██████▎   | 63/100 [02:26<01:24,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 63/100, Loss: 0.49898\n",
            "Epoch: 64/100, Batch: 501/714.939453125 Loss: 0.49764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 64/100 [02:28<01:20,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 64/100, Loss: 0.49899\n",
            "Epoch: 65/100, Batch: 501/714.939453125 Loss: 0.49799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 65/100 [02:30<01:19,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 65/100, Loss: 0.49902\n",
            "Epoch: 66/100, Batch: 501/714.939453125 Loss: 0.49743\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 66%|██████▌   | 66/100 [02:33<01:17,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 66/100, Loss: 0.49901\n",
            "Epoch: 67/100, Batch: 501/714.939453125 Loss: 0.49802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 67/100 [02:35<01:14,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 67/100, Loss: 0.49898\n",
            "Epoch: 68/100, Batch: 501/714.939453125 Loss: 0.49810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 68/100 [02:37<01:14,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 68/100, Loss: 0.49896\n",
            "Epoch: 69/100, Batch: 501/714.939453125 Loss: 0.49801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 69%|██████▉   | 69/100 [02:40<01:11,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 69/100, Loss: 0.49893\n",
            "Epoch: 70/100, Batch: 501/714.939453125 Loss: 0.49804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 70/100 [02:42<01:08,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 70/100, Loss: 0.49898\n",
            "Epoch: 71/100, Batch: 501/714.939453125 Loss: 0.49791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 71/100 [02:44<01:06,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 71/100, Loss: 0.49893\n",
            "Epoch: 72/100, Batch: 501/714.939453125 Loss: 0.49778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 72/100 [02:46<01:04,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 72/100, Loss: 0.49890\n",
            "Epoch: 73/100, Batch: 501/714.939453125 Loss: 0.49799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 73/100 [02:49<01:01,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 73/100, Loss: 0.49900\n",
            "Epoch: 74/100, Batch: 501/714.939453125 Loss: 0.49779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 74%|███████▍  | 74/100 [02:51<01:00,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 74/100, Loss: 0.49894\n",
            "Epoch: 75/100, Batch: 501/714.939453125 Loss: 0.49775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 75/100 [02:53<00:57,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 75/100, Loss: 0.49890\n",
            "Epoch: 76/100, Batch: 501/714.939453125 Loss: 0.49741\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 76/100 [02:55<00:54,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 76/100, Loss: 0.49891\n",
            "Epoch: 77/100, Batch: 501/714.939453125 Loss: 0.49816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 77%|███████▋  | 77/100 [02:58<00:53,  2.32s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 77/100, Loss: 0.49893\n",
            "Epoch: 78/100, Batch: 501/714.939453125 Loss: 0.49772\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 78/100 [03:00<00:51,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 78/100, Loss: 0.49898\n",
            "Epoch: 79/100, Batch: 501/714.939453125 Loss: 0.49792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 79/100 [03:03<00:48,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 79/100, Loss: 0.49898\n",
            "Epoch: 80/100, Batch: 501/714.939453125 Loss: 0.49797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 80/100 [03:05<00:46,  2.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 80/100, Loss: 0.49888\n",
            "Epoch: 81/100, Batch: 501/714.939453125 Loss: 0.49800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 81%|████████  | 81/100 [03:07<00:43,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 81/100, Loss: 0.49895\n",
            "Epoch: 82/100, Batch: 501/714.939453125 Loss: 0.49799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 82/100 [03:09<00:40,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 82/100, Loss: 0.49892\n",
            "Epoch: 83/100, Batch: 501/714.939453125 Loss: 0.49780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 83/100 [03:12<00:38,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 83/100, Loss: 0.49890\n",
            "Epoch: 84/100, Batch: 501/714.939453125 Loss: 0.49754\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 84/100 [03:14<00:36,  2.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 84/100, Loss: 0.49890\n",
            "Epoch: 85/100, Batch: 501/714.939453125 Loss: 0.49801\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 85/100 [03:16<00:33,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 85/100, Loss: 0.49896\n",
            "Epoch: 86/100, Batch: 501/714.939453125 Loss: 0.49815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 86%|████████▌ | 86/100 [03:18<00:31,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 86/100, Loss: 0.49895\n",
            "Epoch: 87/100, Batch: 501/714.939453125 Loss: 0.49788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 87/100 [03:21<00:29,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 87/100, Loss: 0.49877\n",
            "Epoch: 88/100, Batch: 501/714.939453125 Loss: 0.49799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 88/100 [03:23<00:26,  2.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 88/100, Loss: 0.49891\n",
            "Epoch: 89/100, Batch: 501/714.939453125 Loss: 0.49780\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 89%|████████▉ | 89/100 [03:25<00:24,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 89/100, Loss: 0.49890\n",
            "Epoch: 90/100, Batch: 501/714.939453125 Loss: 0.49783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 90/100 [03:27<00:22,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 90/100, Loss: 0.49891\n",
            "Epoch: 91/100, Batch: 501/714.939453125 Loss: 0.49793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 91/100 [03:30<00:20,  2.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 91/100, Loss: 0.49887\n",
            "Epoch: 92/100, Batch: 501/714.939453125 Loss: 0.49760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 92/100 [03:32<00:18,  2.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 92/100, Loss: 0.49891\n",
            "Epoch: 93/100, Batch: 501/714.939453125 Loss: 0.49789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 93/100 [03:34<00:16,  2.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 93/100, Loss: 0.49883\n",
            "Epoch: 94/100, Batch: 501/714.939453125 Loss: 0.49775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 94%|█████████▍| 94/100 [03:37<00:13,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 94/100, Loss: 0.49893\n",
            "Epoch: 95/100, Batch: 501/714.939453125 Loss: 0.49809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 95/100 [03:39<00:11,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 95/100, Loss: 0.49883\n",
            "Epoch: 96/100, Batch: 501/714.939453125 Loss: 0.49778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 96/100 [03:41<00:09,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 96/100, Loss: 0.49889\n",
            "Epoch: 97/100, Batch: 501/714.939453125 Loss: 0.49810\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 97%|█████████▋| 97/100 [03:43<00:06,  2.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 97/100, Loss: 0.49883\n",
            "Epoch: 98/100, Batch: 501/714.939453125 Loss: 0.49737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 98%|█████████▊| 98/100 [03:46<00:04,  2.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 98/100, Loss: 0.49886\n",
            "Epoch: 99/100, Batch: 501/714.939453125 Loss: 0.49781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 99/100 [03:48<00:02,  2.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 99/100, Loss: 0.49889\n",
            "Epoch: 100/100, Batch: 501/714.939453125 Loss: 0.49804\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:50<00:00,  2.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100/100, Loss: 0.49885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "y0rt5W2ELLvP",
        "outputId": "1496eda5-a125-4407-8d9a-2577002c8a4e"
      },
      "source": [
        "# visualization loss\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(lst_loss, marker='s')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Word2Vec Skip-gram Model')\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43pOYRh-MX_F",
        "outputId": "40cc92ae-ed28-4515-dc8f-ddec802b38d5"
      },
      "source": [
        "#計算字詞相似度\n",
        "\n",
        "def get_similarity(word, top_k, model, word2idx, idx2word):\n",
        "    W = (model.in_embedding.weight.data + model.out_embedding.weight.data) / 2\n",
        "    idx = word2idx.get(word, None)\n",
        "    \n",
        "    if not idx:\n",
        "        # 當出現不在字典中的字詞時，顯示Out of vocabulary error\n",
        "        raise ValueError(\"Out of vocabulary\")\n",
        "    else:\n",
        "        x = W[idx]\n",
        "        \n",
        "        # 使用cosine相似計算字詞間的相似程度\n",
        "        cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
        "        _, topk = torch.topk(cos, top_k+1)\n",
        "        \n",
        "        for i in topk[1:]:\n",
        "            print(f\"cosine sim={cos[int(i)]:.3f}: {idx2word[int(i)]}.\")\n",
        "\n",
        "get_similarity('love', 4, model, word2idx, idx2word)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine sim=0.342: burnham.\n",
            "cosine sim=0.332: natural-gas.\n",
            "cosine sim=0.325: egyptian.\n",
            "cosine sim=0.322: chose.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_tL9g0oMcCT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}